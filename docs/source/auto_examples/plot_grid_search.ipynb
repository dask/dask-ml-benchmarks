{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n.. _plot_grid_search.py\n\nGrid search comparision\n=======================\n\nThis example shows the comparison of Dask-ML's grid search and Scikit-Learn's\ngrid search, and is a modification of a Scikit-Learn example at\n`\"Sample pipeline for text feature extraction and evaluation\"\n<http://scikit-learn.org/stable/auto_examples/model_selection/grid_search_text_feature_extraction.html>`_.\n\nIn this example, the Dask-ML grid search does less computation because it\ncaches ``fit`` results. See the documentation for a good illustration for this\nbenchmark:\nhttps://dask-ml.readthedocs.io/en/latest/hyper-parameter-search.html.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import fetch_20newsgroups\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nimport dask_ml.model_selection\nimport sklearn.model_selection\n\nfrom distributed import Client\nfrom distributed.metrics import time\n\nclient = Client()\n\ncategories = [\"alt.atheism\", \"talk.religion.misc\", \"sci.space\", \"sci.med\"]\ndata = sklearn.datasets.fetch_20newsgroups(\n    subset=\"train\", categories=categories\n)\n\nX = data.data\ny = data.target\ndoc_lengths = [len(doc) for doc in X]\nprint(\n    \"Dataset has {} documents. Median length is {} words\".format(\n        len(data.filenames), np.median(doc_lengths)\n    )\n)\nprint(\"Document categories: {}\".format(categories))\n\nparams = {\n    \"tfidf__norm\": [\"l1\", \"l2\"],\n    \"tfidf__binary\": [True, False],\n    \"clf__alpha\": np.logspace(-6, -3, num=4),\n    \"clf__loss\": [\"hinge\", \"log\", \"modified_huber\"],\n    \"clf__penalty\": [\"l1\", \"l2\"],\n}\npipeline = Pipeline(\n    [\n        (\"tfidf\", TfidfVectorizer()),\n        (\"clf\", SGDClassifier(tol=1e-3)),\n    ]\n)\n\ndata = []\n\nstart = time()\ngrid_sklearn = sklearn.model_selection.GridSearchCV(\n    pipeline, params, n_jobs=-1\n)\ngrid_sklearn.fit(X, y)\ndata += [\n    {\n        \"library\": \"scikit-learn\",\n        \"time\": time() - start,\n        \"best_score\": grid_sklearn.best_score_,\n        \"best_params\": grid_sklearn.best_params_,\n    }\n]\n\nstart = time()\ngrid_dask = dask_ml.model_selection.GridSearchCV(pipeline, params)\ngrid_dask.fit(X, y)\ndata += [\n    {\n        \"library\": \"dask-ml\",\n        \"time\": time() - start,\n        \"best_score\": grid_dask.best_score_,\n        \"best_params\": grid_dask.best_params_,\n    }\n]\nprint(\"Best score: \", grid_dask.best_score_)\nprint(\"Best parameter set:\")\npprint(grid_dask.best_params_)\n\n\ndf = pd.DataFrame(data)\nax = df.plot.bar(x=\"library\", y=\"time\", legend=False)\nax.set_ylabel(\"Time (s)\")\nplt.xticks(rotation=0)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}